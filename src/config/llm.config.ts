/**
 * LLM (Large Language Model) configuration.
 */
const llmConfig = {
  LLM_ROLE_USER: "user" as string,
  LLM_ROLE_ASSISTANT: "assistant" as string, 
  LLM_ROLE_SYSTEM: "system" as string,
  DEFAULT_MIN_RETRY_DELAY_MILLIS: 20 * 1000,
  DEFAULT_MAX_RETRY_ADDITIONAL_MILLIS: 30 * 1000,
  DEFAULT_REQUEST_WAIT_TIMEOUT_MILLIS: 7 * 60 * 1000,
  DEFAULT_INVOKE_LLM_NUM_ATTEMPTS: 3,
  COMPLETION_MAX_TOKENS_LIMIT_BUFFER: 5,
  COMPLETION_TOKENS_REDUCE_MIN_RATIO: 0.75, 
  PROMPT_TOKENS_REDUCE_MIN_RATIO: 0.85, 
  MODEL_CHARS_PER_TOKEN_ESTIMATE: 2.8,
  DEFAULT_ZERO_TEMP: 0,
  DEFAULT_TOP_P_LOWEST: 0,
  DEFAULT_TOP_P_VLOW: 0.00001,
  DEFAULT_TOP_K_LOWEST: 1,
  LLM_UTF8_ENCODING: "utf8",
  LLM_RESPONSE_JSON_CONTENT_TYPE: "application/json",
  LLM_RESPONSE_ANY_CONTENT_TYPE: "*/*",
  DEFAULT_VECTOR_DIMENSIONS_AMOUNT: 1536,
  VECTOR_SIMILARITY_TYPE: "euclidean",  // euclidean | cosine | dotProduct
  VECTOR_QUANTIZATION_TYPE: "scalar",   // scalar | binary
  VECTOR_SEARCH_NUM_CANDIDATES: 150,
  VECTOR_SEARCH_NUM_LIMIT: 6,
  PROBLEMATIC_SHUTDOWN_LLM_PROVIDER: "VertexAIGemini",
} as const;

export default llmConfig;